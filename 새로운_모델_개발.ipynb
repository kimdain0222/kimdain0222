{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdain0222/kimdain0222/blob/main/%EC%83%88%EB%A1%9C%EC%9A%B4_%EB%AA%A8%EB%8D%B8_%EA%B0%9C%EB%B0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import"
      ],
      "metadata": {
        "id": "6BlyDo21eF5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"asjad99/mimiciii\")\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5F7CmREeI6H",
        "outputId": "9aef5ee3-728b-4984-8008-ef07bb19c59c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/kaggle/input/mimiciii\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_PATIENTS = pd.read_csv('/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv')\n",
        "df_CHARTEVENTS = pd.read_csv('/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/CHARTEVENTS.csv')\n",
        "df_ADMISSIONS = pd.read_csv('/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv')\n",
        "df_D_ITEMS = pd.read_csv('/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4//D_ITEMS.csv')\n",
        "\n",
        "df_ADMISSIONS = df_ADMISSIONS[df_ADMISSIONS['subject_id'] != 10120]\n",
        "df_PATIENTS = df_PATIENTS[df_PATIENTS['subject_id'] != 10120]\n",
        "\n",
        "df_PATIENTS = df_PATIENTS.loc[:,['subject_id','gender']]"
      ],
      "metadata": {
        "id": "Y33TQb-VeMyS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 전처리\n"
      ],
      "metadata": {
        "id": "OVbBvCEwePer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_CHARTEVENTS['value'] = pd.to_numeric(df_CHARTEVENTS['value'], errors='coerce')\n",
        "df_pivot = df_CHARTEVENTS[df_CHARTEVENTS['itemid'].isin([211, 618, 646])].loc[:,['subject_id','itemid','value','charttime']]\\\n",
        ".pivot_table(\n",
        "    index=['subject_id', 'charttime'],\n",
        "    columns='itemid',\n",
        "    values='value'\n",
        ").reset_index()\n",
        "df_pivot = df_pivot.sort_values(by=['subject_id', 'charttime'])\n",
        "df_pivot = df_pivot.rename(columns={211: 'Heart_Rate', 618: 'Resp_Rate', 646: 'SpO2'})\n",
        "\n",
        "# NAN 채우기\n",
        "# 각 subject_id별 평균 구하기\n",
        "subject_means = df_pivot.groupby(\"subject_id\")[[\"Heart_Rate\", \"Resp_Rate\", \"SpO2\"]].transform(\"mean\")\n",
        "\n",
        "# NaN 값을 각 subject의 평균으로 채우기\n",
        "df_pivot_filled = df_pivot.copy()\n",
        "df_pivot_filled[[\"Heart_Rate\", \"Resp_Rate\", \"SpO2\"]] = df_pivot[[\"Heart_Rate\", \"Resp_Rate\", \"SpO2\"]].fillna(subject_means)\n",
        "\n",
        "# datetime 형식으로 변환\n",
        "df_pivot_filled['charttime'] = pd.to_datetime(df_pivot_filled['charttime'])\n",
        "\n",
        "df_ADMISSIONS_flag = df_ADMISSIONS.loc[:,['subject_id','hospital_expire_flag']]\n",
        "\n",
        "# 조인\n",
        "df_merged = pd.merge(df_pivot_filled, df_ADMISSIONS_flag, on='subject_id', how='left')"
      ],
      "metadata": {
        "id": "7tLViPFGeWyG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ADMISSIONS_select = df_ADMISSIONS.loc[:,['subject_id','admission_type','admission_location','discharge_location',\n",
        "                     'insurance','marital_status','ethnicity','diagnosis','hospital_expire_flag']]\n",
        "\n",
        "df_ADMISSIONS_select_s = pd.merge(df_PATIENTS, df_ADMISSIONS_select, on='subject_id', how='left').drop(['hospital_expire_flag'],axis=1)\n",
        "df_mgd = pd.merge(df_merged, df_ADMISSIONS_select_s, on='subject_id', how='left')\n"
      ],
      "metadata": {
        "id": "n74JZPNseZJs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 모델 구현\n"
      ],
      "metadata": {
        "id": "E9yTAI70ecqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class LSTM_XGBoost_Model:\n",
        "    def __init__(self, lstm_input_dim=3, lstm_hidden_dim=64, random_state=42):\n",
        "        self.lstm_input_dim = lstm_input_dim\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.random_state = random_state\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.static_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "        self.xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state)\n",
        "        self.lstm_model = self._build_lstm().to(self.device)\n",
        "\n",
        "    def _build_lstm(self):\n",
        "        class LSTMFeatureExtractor(nn.Module):\n",
        "            def __init__(self, input_dim, hidden_dim):\n",
        "                super().__init__()\n",
        "                self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "            def forward(self, x):\n",
        "                _, (hn, _) = self.lstm(x)\n",
        "                return hn.squeeze(0)  # (batch, hidden_dim)\n",
        "\n",
        "        return LSTMFeatureExtractor(self.lstm_input_dim, self.lstm_hidden_dim)\n",
        "\n",
        "    def _prepare_sequences(self, df, vitals):\n",
        "        df_sorted = df.sort_values(by=['subject_id', 'charttime'])\n",
        "        sequences = df_sorted.groupby('subject_id')[vitals].apply(lambda x: torch.tensor(x.values, dtype=torch.float32))\n",
        "        padded_seqs = pad_sequence(sequences.tolist(), batch_first=True)\n",
        "        return padded_seqs, sequences.index.tolist()  # tensor, subject_ids\n",
        "\n",
        "    def _prepare_static_features(self, df, static_cols, subject_ids, fit=True):\n",
        "        static_df = df.groupby('subject_id').last().loc[subject_ids]\n",
        "        if fit:\n",
        "            static_encoded = self.static_encoder.fit_transform(static_df[static_cols])\n",
        "        else:\n",
        "            static_encoded = self.static_encoder.transform(static_df[static_cols])\n",
        "        return static_encoded, static_df['hospital_expire_flag'].astype(int).values\n",
        "\n",
        "    def fit(self, df, vitals, static_cols, target_col='hospital_expire_flag', test_size=0.2):\n",
        "        padded_seqs, subject_ids = self._prepare_sequences(df, vitals)\n",
        "        X_static, y = self._prepare_static_features(df, static_cols, subject_ids, fit=True)\n",
        "\n",
        "        self.lstm_model.eval()\n",
        "        with torch.no_grad():\n",
        "            lstm_features = self.lstm_model(padded_seqs.to(self.device)).cpu().numpy()\n",
        "            if lstm_features.ndim == 1:\n",
        "                lstm_features = lstm_features.reshape(1, -1)\n",
        "\n",
        "        X_static = np.asarray(X_static)\n",
        "        if X_static.ndim == 1:\n",
        "            X_static = X_static.reshape(1, -1)\n",
        "\n",
        "        X = np.concatenate([X_static, lstm_features], axis=1)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, stratify=y, random_state=self.random_state)\n",
        "\n",
        "        self.xgb_model.fit(X_train, y_train)\n",
        "        y_pred = self.xgb_model.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_pred)\n",
        "        print(f\"✅ Train/Test AUC-ROC: {auc:.4f}\")\n",
        "        return auc\n",
        "\n",
        "    def predict(self, df, vitals, static_cols):\n",
        "        padded_seqs, subject_ids = self._prepare_sequences(df, vitals)\n",
        "        X_static, _ = self._prepare_static_features(df, static_cols, subject_ids, fit=False)\n",
        "\n",
        "        self.lstm_model.eval()\n",
        "        with torch.no_grad():\n",
        "            lstm_features = self.lstm_model(padded_seqs.to(self.device)).cpu().numpy()\n",
        "            if lstm_features.ndim == 1:\n",
        "                lstm_features = lstm_features.reshape(1, -1)\n",
        "\n",
        "        X_static = np.asarray(X_static)\n",
        "        if X_static.ndim == 1:\n",
        "            X_static = X_static.reshape(1, -1)\n",
        "\n",
        "        X = np.concatenate([X_static, lstm_features], axis=1)\n",
        "        preds = self.xgb_model.predict_proba(X)[:, 1]\n",
        "        return pd.DataFrame({'subject_id': subject_ids, 'pred_prob': preds})\n"
      ],
      "metadata": {
        "id": "UDcMqHbUebCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "class LSTM_XGBoost_Model:\n",
        "    def __init__(self, lstm_input_dim=3, lstm_hidden_dim=64, random_state=42):\n",
        "        self.lstm_input_dim = lstm_input_dim\n",
        "        self.lstm_hidden_dim = lstm_hidden_dim\n",
        "        self.random_state = random_state\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.static_encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "        self.xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=random_state)\n",
        "        self.lstm_model = self._build_lstm().to(self.device)\n",
        "\n",
        "    def _build_lstm(self):\n",
        "        class LSTMFeatureExtractor(nn.Module):\n",
        "            def __init__(self, input_dim, hidden_dim):\n",
        "                super().__init__()\n",
        "                self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "            def forward(self, x):\n",
        "                _, (hn, _) = self.lstm(x)\n",
        "                return hn.squeeze(0)  # (batch, hidden_dim)\n",
        "\n",
        "        return LSTMFeatureExtractor(self.lstm_input_dim, self.lstm_hidden_dim)\n",
        "\n",
        "    def _prepare_sequences(self, df, vitals):\n",
        "        df_sorted = df.sort_values(by=['subject_id', 'charttime'])\n",
        "        sequences = df_sorted.groupby('subject_id')[vitals].apply(lambda x: torch.tensor(x.values, dtype=torch.float32))\n",
        "        padded_seqs = pad_sequence(sequences.tolist(), batch_first=True)\n",
        "        return padded_seqs, sequences.index.tolist()\n",
        "\n",
        "    def _prepare_static_features(self, df, static_cols, subject_ids):\n",
        "        static_df = df.groupby('subject_id').last().loc[subject_ids]\n",
        "        static_encoded = self.static_encoder.fit_transform(static_df[static_cols])\n",
        "        return static_encoded, static_df['hospital_expire_flag'].astype(int).values\n",
        "\n",
        "    def fit(self, df, vitals, static_cols, target_col='hospital_expire_flag', test_size=0.2):\n",
        "        # Step 1: 시계열 시퀀스 처리\n",
        "        padded_seqs, subject_ids = self._prepare_sequences(df, vitals)\n",
        "\n",
        "        # Step 2: 정적 변수 인코딩 + 정답\n",
        "        X_static, y = self._prepare_static_features(df, static_cols, subject_ids, fit=True)\n",
        "\n",
        "        # Step 3: LSTM feature 추출\n",
        "        self.lstm_model.eval()\n",
        "        with torch.no_grad():\n",
        "            lstm_features = self.lstm_model(padded_seqs.to(self.device)).cpu().numpy()\n",
        "\n",
        "        # Step 4: 차원 문제 방지 (안전하게 reshape)\n",
        "        X_static = np.asarray(X_static)\n",
        "        lstm_features = np.asarray(lstm_features)\n",
        "\n",
        "        if X_static.ndim == 1:\n",
        "            X_static = X_static.reshape(1, -1)\n",
        "        if lstm_features.ndim == 1:\n",
        "            lstm_features = lstm_features.reshape(1, -1)\n",
        "\n",
        "        # Step 5: 두 feature 결합\n",
        "        try:\n",
        "            X = np.concatenate([X_static, lstm_features], axis=1)\n",
        "        except Exception as e:\n",
        "            print(\"❌ Concatenation Error\")\n",
        "            print(\"X_static shape:\", X_static.shape)\n",
        "            print(\"lstm_features shape:\", lstm_features.shape)\n",
        "            raise e\n",
        "\n",
        "        # Step 6: 학습\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, stratify=y, random_state=self.random_state)\n",
        "\n",
        "        self.xgb_model.fit(X_train, y_train)\n",
        "        y_pred = self.xgb_model.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, y_pred)\n",
        "        print(f\"✅ Train/Test AUC-ROC: {auc:.4f}\")\n",
        "        return auc\n",
        "\n",
        "\n",
        "    def predict(self, df, vitals, static_cols):\n",
        "        padded_seqs, subject_ids = self._prepare_sequences(df, vitals)\n",
        "        static_df = df.groupby('subject_id').last().loc[subject_ids]\n",
        "        X_static = self.static_encoder.transform(static_df[static_cols])\n",
        "\n",
        "        self.lstm_model.eval()\n",
        "        with torch.no_grad():\n",
        "            lstm_features = self.lstm_model(padded_seqs.to(self.device)).cpu().numpy()\n",
        "\n",
        "        X = np.concatenate([X_static, lstm_features], axis=1)\n",
        "        preds = self.xgb_model.predict_proba(X)[:, 1]\n",
        "        return pd.DataFrame({'subject_id': subject_ids, 'pred_prob': preds})\n"
      ],
      "metadata": {
        "id": "7FrojrTqfJhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "vitals = ['Heart_Rate', 'Resp_Rate', 'SpO2']\n",
        "\n",
        "static_cols = ['gender', 'admission_type', 'admission_location',\n",
        "               'discharge_location', 'insurance', 'marital_status',\n",
        "               'ethnicity', 'diagnosis']\n",
        "\n",
        "\n",
        "subject_ids = df_mgd['subject_id'].unique()\n",
        "train_ids, test_ids = train_test_split(\n",
        "    subject_ids,\n",
        "    test_size=0.2,\n",
        "    stratify=df_mgd.groupby('subject_id')['hospital_expire_flag'].first(),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "df_train = df_mgd[df_mgd['subject_id'].isin(train_ids)].copy()\n",
        "df_test = df_mgd[df_mgd['subject_id'].isin(test_ids)].copy()\n",
        "\n",
        "# 모델 정의 및 학습\n",
        "model = LSTM_XGBoost_Model()\n",
        "model.fit(df_train, vitals=vitals, static_cols=static_cols)\n",
        "\n",
        "# 예측\n",
        "preds_df = model.predict(df_test, vitals=vitals, static_cols=static_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "B_5Prt1if8wR",
        "outputId": "6ecc0a11-fef2-4390-bb2c-d1fcc5a0f742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "LSTM_XGBoost_Model._prepare_static_features() got an unexpected keyword argument 'fit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-1597909745.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 모델 정의 및 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_XGBoost_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvitals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvitals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatic_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-21-2722272783.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, vitals, static_cols, target_col, test_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Step 2: 정적 변수 인코딩 + 정답\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mX_static\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_static_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Step 3: LSTM feature 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: LSTM_XGBoost_Model._prepare_static_features() got an unexpected keyword argument 'fit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KiUZEOvHgEAx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}